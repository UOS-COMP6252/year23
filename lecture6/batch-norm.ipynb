{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/hikmatfarhat-ndu/pytorch/blob/main/batch-norm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HTsa4o4TAkhT"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision as vision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import SGD,Adam"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.dp=nn.Dropout(p=0.6)\n",
    "    def forward(self,x):\n",
    "        return self.dp(x)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training vs test/validate\n",
    "- Implementation in PyTorch opts for \n",
    "- $\\frac{1}{1-p}$ during training\n",
    "- Identity during testing/validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=torch.tensor([[1,2],[3,4]],dtype=torch.float32).unsqueeze(0)\n",
    "dp=DP()\n",
    "dp.train()\n",
    "print(dp(x))\n",
    "dp.eval()\n",
    "dp(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch normalization     \n",
    "Given a mini-batch of tensors $x_{ci}$ of dimension (S,C,H,W) where $c$ is the channel index and $i$ collectively refers to all other dimensions. \n",
    "\n",
    "Let $N=S\\times H\\times W$. Batch normalization computes the mean and variance of the batch (per channel) according to\n",
    "  $$\n",
    "    \\begin{align*}\n",
    "    \\mu_c&=\\frac{1}{N}\\sum_{i=1}^N x_{ci}\\\\\n",
    "    \\sigma^2_c&=\\frac{1}{N}\\sum_{i=1}^N \\left(x_{ci}-\\mu_c\\right)^2\n",
    "    \\end{align*}\n",
    "$$\n",
    "\n",
    "The normalized inputs are computed as follows:\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\hat{x}_{ci}=\\frac{x_{ic}-\\mu_c}{\\sqrt{\\sigma^2_c+\\epsilon}}\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "Therefore, for each channel, the $\\hat{x}_{ci}$ have zero mean and unit variance. The output of the batch normalization layer is given by\n",
    "$$\n",
    "\\begin{align*}\n",
    "y_{ic}=\\gamma \\hat{x}_{ic}+\\beta\n",
    "\\end{align*}\n",
    "$$\n",
    "Where $\\gamma$ and $\\beta$ are **learnable** parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example\n",
    "- For simplicity we consider a  tensor with a single channel\n",
    "- Recall that batch normalization is done for each channel independently\n",
    "- In the example below we create an arbitrary tensor ```a```  of size ```(2,1,22)```\n",
    "- It represents two samples, each with a single channel representing a 2x2 tensor.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=torch.tensor([[1,2],[3,4]],dtype=torch.float32).unsqueeze(0)\n",
    "y=torch.tensor([[5,6],[7,18]],dtype=torch.float32).unsqueeze(0)\n",
    "\n",
    "a=torch.stack([x,y])\n",
    "print(list(a.size()))\n",
    "print(a.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Manual Computation vs Normalization Layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually \n",
    "var=a.var([0,2,3],unbiased=False)\n",
    "mean=a.mean([0,2,3])\n",
    "(a-mean)/torch.sqrt(var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using PyTorch BatchNorm2d\n",
    "with torch.no_grad():\n",
    "    norm=nn.BatchNorm2d(num_features=1)  \n",
    "    b=norm(a)\n",
    "b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolution Network for CIFAR10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to ensure reproducibility\n",
    "seed=9 \n",
    "torch.manual_seed(seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic=True\n",
    "# use/not use batch normalization\n",
    "use_BN=False\n",
    "epochs=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.ToTensor()\n",
    "dataset_train=vision.datasets.CIFAR10(\".\",download=True,train=True,transform=transform)\n",
    "dataset_test=vision.datasets.CIFAR10(\".\",download=True,train=False,transform=transform)\n",
    "loader_train=DataLoader(dataset_train,batch_size=64,shuffle=True,num_workers=2)\n",
    "loader_test=DataLoader(dataset_test,batch_size=512,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "  def __init__(self,norm_layers=True):\n",
    "    super().__init__()\n",
    "    self.norm_layers=norm_layers\n",
    "    # self.norm1=nn.BatchNorm2d(32)\n",
    "    # self.norm2=nn.BatchNorm2d(32)\n",
    "    # self.norm3=nn.BatchNorm2d(64)\n",
    "    # self.norm4=nn.BatchNorm2d(64)\n",
    "    self.norm1=nn.Dropout2d(0.5)\n",
    "    self.norm2=nn.Dropout2d(0.5)\n",
    "    self.norm3=nn.Dropout2d(0.5)\n",
    "    self.norm4=nn.Dropout2d(0.5)\n",
    "    self.relu=nn.ReLU()\n",
    "    # input is (*,3,32,32)\n",
    "    self.conv1=nn.Conv2d(in_channels=3,out_channels=32,kernel_size=3)\n",
    "    # input is (*,32,30,30)\n",
    "    self.conv2=nn.Conv2d(in_channels=32,out_channels=32,kernel_size=3)\n",
    "    self.conv2a=nn.Conv2d(in_channels=32,out_channels=32,kernel_size=3)\n",
    "    # input is (*,32,28,28)\n",
    "    self.pool1=nn.MaxPool2d(kernel_size=(2,2))\n",
    "    # input is (*,32,14,14)\n",
    "    self.conv3=nn.Conv2d(in_channels=32,out_channels=64,kernel_size=3)\n",
    "    # input is (*,64,12,12)\n",
    "    self.conv4=nn.Conv2d(in_channels=64,out_channels=64,kernel_size=3)\n",
    "    self.conv4a=nn.Conv2d(in_channels=64,out_channels=64,kernel_size=3)\n",
    "    # input is (*,64,10,10)\n",
    "    self.pool2=nn.MaxPool2d(kernel_size=(2,2))\n",
    "    # input is (*,64,5,5)\n",
    "    self.flatten=nn.Flatten()\n",
    "    # input is (*,64x5x5)\n",
    "    self.fc1=nn.Linear(in_features=5*5*64,out_features=128)\n",
    "    self.fc2=nn.Linear(in_features=128,out_features=10)\n",
    "\n",
    "  def forward(self,x):\n",
    "    x=self.conv1(x)\n",
    "    if self.norm_layers:\n",
    "      x=self.norm1(x)\n",
    "    x=self.relu(x)\n",
    "    x=self.conv2(x)\n",
    "    if self.norm_layers:\n",
    "      x=self.norm2(x)\n",
    "    x=self.relu(x)\n",
    "    x=self.pool1(x)\n",
    "    \n",
    "    x=self.conv3(x)\n",
    "    if self.norm_layers:\n",
    "      x=self.norm3(x)\n",
    "    x=self.relu(x)\n",
    "    x=self.conv4(x)\n",
    "    if self.norm_layers:\n",
    "      x=self.norm4(x)\n",
    "    x=self.relu(x)\n",
    "    x=self.pool2(x)\n",
    "    \n",
    "    x=self.flatten(x)\n",
    "    x=self.fc1(x)\n",
    "    x=self.relu(x)\n",
    "    x=self.fc2(x)\n",
    "    return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(model,batch,loss_fn):\n",
    "    imgs,labels=batch\n",
    "    imgs=imgs.cuda()\n",
    "    labels=labels.cuda()\n",
    "    outputs=model(imgs)\n",
    "    _,pred=torch.max(outputs,dim=1)\n",
    "    acc=torch.sum(pred==labels).item()\n",
    "    loss=loss_fn(outputs,labels)\n",
    "    return loss,torch.tensor(acc/len(labels))\n",
    "\n",
    "@torch.no_grad() \n",
    "def evaluate(model,loader,loss_fn):\n",
    "    model.eval()\n",
    "    # crit is a list of pairs of tensors\n",
    "    crit=[accuracy(model,batch,loss_fn) for batch in loader]\n",
    "    crit=torch.tensor(crit)\n",
    "    m=crit.mean(dim=0)\n",
    "    loss=m[0]\n",
    "    acc=m[1]\n",
    "    return loss,acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Net(norm_layers=use_BN).cuda()\n",
    "optimizer=Adam(model.parameters())\n",
    "#optimizer=SGD(model.parameters(),lr=0.5)\n",
    "loss_fn=nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import datetime\n",
    "# To display tensorboard inside the notebook\n",
    "%load_ext tensorboard\n",
    "current=datetime.datetime.now()\n",
    "log_dir = 'logs/tensorboard/' + ('with BN-' if use_BN else 'withou BN-')+current.strftime(\"%c\")\n",
    "writer=SummaryWriter(log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping():\n",
    "    def __init__(self,patience=4,tolerance=0):\n",
    "        self.patience=patience\n",
    "        self.tolerance=tolerance\n",
    "        self.min_loss=float('inf')\n",
    "        self.count=0\n",
    "    def __call__(self,loss):\n",
    "        if loss<self.min_loss:\n",
    "            self.count=0\n",
    "            self.min_loss=loss\n",
    "            return False\n",
    "        elif loss>self.min_loss+self.tolerance:\n",
    "            self.count+=1\n",
    "            if self.count>self.patience:\n",
    "                return True\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigger=True\n",
    "es=EarlyStopping()\n",
    "from tqdm import tqdm\n",
    "for epoch in range(epochs):\n",
    "  loop=tqdm(loader_train)\n",
    "  loop.set_description(f\"Epoch [{epoch+1}/{epochs}]\")\n",
    "  epoch_loss=0.\n",
    "  model.train()\n",
    "  for (imgs,labels) in loop:\n",
    "    optimizer.zero_grad()\n",
    "    imgs=imgs.cuda()\n",
    "    labels=labels.cuda()\n",
    "    outputs=model(imgs)\n",
    "    loss=loss_fn(outputs,labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    epoch_loss=0.9*epoch_loss+0.1*loss.item()\n",
    "    loop.set_postfix(loss=epoch_loss)\n",
    "   \n",
    "  t_loss,t_acc=evaluate(model,loader_train,loss_fn)\n",
    "  v_loss,v_acc=evaluate(model,loader_test,loss_fn)\n",
    "  writer.add_scalar(\"Epoch loss\",epoch_loss,epoch)\n",
    "  writer.add_scalars(\"loss\",{'train':t_loss,'valid':v_loss},epoch)\n",
    "  writer.add_scalars(\"acc\",{'train':t_acc,'valid':v_acc},epoch)\n",
    "  if es(v_loss) and trigger:\n",
    "  #   break\n",
    "     print(\"At epoch={} we should stop. Validation accuracy={}\".format(epoch,v_acc))\n",
    "     trigger=False\n",
    "writer.close()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir logs/tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torchmetrics\n",
    "from torchmetrics import ConfusionMatrix\n",
    "conmat=ConfusionMatrix(num_classes=10)\n",
    "conmat=conmat.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total=0\n",
    "correct=0\n",
    "for data in loader_test:\n",
    "  imgs,labels=data\n",
    "  imgs=imgs.cuda()\n",
    "  labels=labels.cuda()\n",
    "  outputs=model(imgs)\n",
    "  # the second return value is the index of the max i.e. argmax\n",
    "  _,predicted=torch.max(outputs.data,1)\n",
    "  correct+=(predicted==labels).sum()\n",
    "  total+=labels.size()[0]\n",
    "  conmat.update(predicted,labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "x=conmat.compute().cpu().numpy()\n",
    "plt.figure(figsize=(10,7))\n",
    "sb.heatmap(x,xticklabels=dataset_train.classes,yticklabels=dataset_train.classes,annot=True,fmt=\".0f\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The rows are the actual images and the columns are the prediction (How can you check?)\n",
    "- While the prediction accuracy is good albeit not impressive\n",
    "- From the confusion matrix we find justifications for the inaccuracies\n",
    "- For example\n",
    "    - most of the incorrect classifications of automobiles were classified as trucks\n",
    "    - most of the incorrect classifications of cats/dogs were classified as dogs/cats\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6 (main, Nov 14 2022, 16:10:14) [GCC 11.3.0]"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
