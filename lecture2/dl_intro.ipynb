{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github",
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/hikmatfarhat-ndu/pytorch/blob/main/dl_intro.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZXG2Gc34Vqio",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# What you will learn in this notebook\n",
    " \n",
    "1. Introduction to supervised learning and classification\n",
    "1. Introduction to loss functions, activation functions, and gradient descent\n",
    "1. Introduction to Pytorch packages, tensors, computation graphs, and gradients\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zpJEiPpbHjjk",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## CIFAR10 Dataset\n",
    "\n",
    "- We use the CIFAR10 dataset to perform binary classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "4j6mq7QsZzsF",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./cifar-10-python.tar.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b90b70fdd22c4251b59abc5f2787608e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/170498071 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./cifar-10-python.tar.gz to .\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "import torchvision as vision\n",
    "\n",
    "cifar10_train=vision.datasets.CIFAR10(\".\",download=True,train=True)# train=True is the default\n",
    "cifar10_test=vision.datasets.CIFAR10(\".\",download=True,train=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m7zBqVB3oCeV",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Data transforms\n",
    "- Recall from last session that CIFAR10 contains a set of images/labels. To use the dataset with PyTorch we need to **transform** the data to tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JziiKBlKnDqH",
    "outputId": "e3603c30-1504-430c-b021-6e9732b0d4b6",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'PIL.Image.Image'> <class 'int'>\n"
     ]
    }
   ],
   "source": [
    "itr=iter(cifar10_train)\n",
    "img,label=next(itr)\n",
    "print(type(img),type(label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "from torchvision.transforms import ToTensor\n",
    "cifar10_train=vision.datasets.CIFAR10(\".\",download=True,train=True,transform=ToTensor())\n",
    "cifar10_test=vision.datasets.CIFAR10(\".\",download=True,train=False,transform=ToTensor())\n",
    "itr=iter(cifar10_train)\n",
    "img,label=next(itr)\n",
    "print(type(img))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Binary classification\n",
    "\n",
    "- The dataset has 10 classes: Airplanes,Cars,Birds,Cats,Deers,Dogs,Frogs,Horses, Ships and Trucks\n",
    "- For simplicity we will rearrange it into only 2 classes\n",
    "    - \"Living things\": Birds, Cats,Deers,Dogs, Frogs, Horses\n",
    "    - \"Machines\": Airplanes, Cars, Shipts and Trucks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Rearrange both the train and test datasets\n",
    "- Why didn't we use ```label=1``` and ```label=0``` in the code below ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "#airplane=0,car=1,bird=2,cat=3,deer=4,dog=5,frog=6,horse=7,ship=8,truck=9\n",
    "features=torch.tensor([0,1,8,9])\n",
    "for i, (img,label) in enumerate(cifar10_train):\n",
    "    if torch.isin(label,features):\n",
    "        cifar10_train.targets[i]=1\n",
    "    else:\n",
    "        cifar10_train.targets[i]=0\n",
    "for i, (img,label) in enumerate(cifar10_test):\n",
    "    if torch.isin(label,features):\n",
    "        cifar10_test.targets[i]=1\n",
    "    else:\n",
    "        cifar10_test.targets[i]=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Stochastic gradient descent\n",
    "\n",
    "- So far the gradient was computed over the whole dataset\n",
    "    - In many situations this is not feasible, e.g. not enough memory\n",
    "- A good approximation is stochastic gradient descent\n",
    "    - The gradient is computed for a single sample\n",
    "- Another, most commonly used varient, is to compute the gradient over a random subset of the dataset (batch)\n",
    "    - Saves memory\n",
    "    - Better chance to escape local minima\n",
    "- We will refer to the above version as stochastic gradient descent (SGD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Data loader\n",
    "- SGD is more efficient when the batches are randomly selected\n",
    "- PyTorch provides a convenient class for operations on batches: ```DataLoader```\n",
    "- ```num_workers``` is the number of threads used for parallel processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "batch_size=64\n",
    "train_loader=DataLoader(cifar10_train,batch_size=batch_size,num_workers=2)\n",
    "test_loader=DataLoader(cifar10_test,batch_size=batch_size,num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'> torch.int64\n",
      "torch.Size([64, 3, 32, 32]) torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "itr=iter(train_loader)\n",
    "imgs,labels=next(itr)\n",
    "print(type(imgs),labels.dtype)\n",
    "print(imgs.shape,labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4udcJFDWf8-8",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "\n",
    "## Logistic Regression\n",
    "\n",
    "- Logistic Regression can be regarded as the **simplest neural network**, a single \"neuron\". \n",
    "- It takes as input a vector of size $n$ and it feeds a single unit (a neuron or perceptron). \n",
    "- The neuron is represented by a vector of **learnable** weights $w$ and bias $b$\n",
    "- The output is the sum of $b$ and the **dot** product between $w$ and the vector input $x$\n",
    "- The result is fed into some function (usually nonlinear) $f$ called the activation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "z&=\\sum_iw_i\\cdot x_i+b\\\\\n",
    "\\hat{y}(x)&=f(z)\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "- Note that because $z$ depends on $W$ and $b$ so does $\\hat{y}$. \n",
    "- Therefore our task is to **learn** the \"best\" values of $W$ and $b$ to model the data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- The input $x$ and $f$ are known whereas $w$ and $b$ are parameters to be determined. \n",
    "- Our goal is to find the _optimal_ $w$ and $b$ such that the output is as *close as possible* to the label associated with the input.\n",
    "![title](https://github.com/hikmatfarhat-ndu/CSC645/blob/master/figures/perceptron.png?raw=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "- How is \"**as close as possible**\" defined? \n",
    "- The dataset is usually a set of pairs $(x,y)$. \n",
    "- We define the loss as the **deviation** between the label $y$ and the result $\\hat{y}=f(z)$\n",
    "\n",
    "$$loss=\\mathcal{L}_{w,b}(y,\\hat{y})$$\n",
    "\n",
    "- The function $\\mathcal{L}$ depends on the problem (for example binary cross entropy, mean squared error,...)\n",
    "\n",
    "- Note that $\\mathcal{L}$ depends on the parameters $w,b$. \n",
    "- Our goal is to find the **optimal** $w,b$ such that $\\mathcal{L}$ is minimal. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wha5x_KeRHkw",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Sigmoid\n",
    "\n",
    "- So far we have not specified the function _f_ that our  model depends on $\\hat{y}=f(z)$. \n",
    "- In this example we use the **sigmoid** function. Given an input _z_ it has the form\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\sigma=\\frac{1}{1+e^{-z}}\n",
    "\\end{align*}\n",
    "$$\n",
    "- The values of $\\sigma$ go from 0 to 1 which we interpret as the probability that the label is 1\n",
    "- $1-\\sigma$ is the probability that the label is 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "id": "wAe6yJrBRN_1",
    "outputId": "7bd84e2d-f3f9-44e0-f6b9-d6565aaff745",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "z=[1/(1+np.exp(-x)) for x in range(-10,11)]\n",
    "plt.plot([x for x in range(-10,11)],z)\n",
    "plt.xticks([t for t in range(-10,11,2)])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_vMc-jV9pIcd",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Flatening the images\n",
    "- The input images have dimensions (3,32,32) (3 channels, 32 height,32 width). \n",
    "- To use them as input to the \"neuron\" we need to \"flatten\" the input\n",
    "- One can use the ```.reshape``` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "UvukYwIicPqx",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 3072]) torch.Size([32])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0, 1])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "itr=iter(train_loader)\n",
    "imgs,labels=next(itr)\n",
    "rimgs=rimgs.reshape(batch_size,-1)\n",
    "print(rimgs.shape,labels.shape)\n",
    "torch.unique(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- ```reshape``` does not work when the size of the datasets is **not** a multiple of the batch size\n",
    "- For CIFAR10 there are 50000 training samples. \n",
    "- That's 781 batches of size 64 and the last has size 16: ```50000=781*64+16```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 3, 32, 32]) torch.Size([16])\n"
     ]
    }
   ],
   "source": [
    "for batch in train_loader:\n",
    "    imgs,labels=batch\n",
    "    \n",
    "print(imgs.shape,labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### use of ```flatten```\n",
    "\n",
    "- It is more convenient to use ```tensor.flatten(start_dim=d)```\n",
    "- Where ```d``` specifies from which dimension to start \"flattening\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([196608]) torch.Size([64, 3072])\n"
     ]
    }
   ],
   "source": [
    "print(imgs.shape)\n",
    "print(imgs.flatten(start_dim=0).shape,imgs.flatten(start_dim=1).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r-VxiVGnp2LC",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Initialize the parameters\n",
    "- The goal is tofind the **optimal** values for the parameters, $w$ and $b$. \n",
    "- Intially we give them random values (for weights) and 0 for the bias as shown below. \n",
    "- Note that\n",
    "    - The `reguires_grad` declares a tensor to be a variable\n",
    "    - In previous versions of Pytorch one needed to declare variables explicitly but this is deprecated now. See [here](https://pytorch.org/docs/stable/autograd.html#variable-deprecated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "koYSysX4gKjr",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "weights=torch.randn(3*32*32,requires_grad=True,dtype=torch.float32)\n",
    "bias=torch.tensor(0.,requires_grad=True,dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1Z9ssRJxX6iw",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Optimization loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "rate=0.015\n",
    "loss_fn=torch.nn.BCELoss()\n",
    "epochs=10\n",
    "for epoch in range(epochs):\n",
    "    for imgs,labels in train_loader:\n",
    "        imgs=imgs.flatten(start_dim=1)\n",
    "        y_hat=torch.matmul(imgs,weights)+bias\n",
    "        y_hat=torch.sigmoid(y_hat)\n",
    "        loss=loss_fn(y_hat,labels.float())\n",
    "        dw,db=torch.autograd.grad(loss,[weights,bias])\n",
    "        #update the weights and bias\n",
    "        weights.data-=rate*dw\n",
    "        bias.data-=rate*db\n",
    "\n",
    "  \n",
    "    print(\"loss {:.4f}\".format(loss.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IJGEPlrz5l0U",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Prediction on the test data\n",
    "\n",
    "- An important measure of any ML method is how well it \"generalizes\". \n",
    "- This is done by using the trained model on **test** data, i.e. data that it **was not** trained on \n",
    "- But he output of our model is the probability that the input is a \"machine\", which could be any value between 0 and 1. \n",
    "- The test labels are discrete values of 0 and 1 so how do we compare them? \n",
    "- We regard a probability $\\ge 0.5$ to be 1 and $< 0.5$ to be 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Measuring accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XttSuF7xuVom",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def predict(loader):\n",
    "    total=0.\n",
    "    for imgs,labels in loader:\n",
    "        imgs=imgs.flatten(start_dim=1)\n",
    "        y_hat=torch.matmul(imgs,weights)+bias\n",
    "        y_hat=torch.sigmoid(y_hat)\n",
    "        ones=y_hat>0.5\n",
    "        ## count how many outputs are equal to the \"true\" labels\n",
    "        r=ones==labels\n",
    "        ## add them to the total\n",
    "        total+=r.sum()\n",
    "    \n",
    "    return total/len(loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qdCBzLnqc6tO",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Abstracting the model and training pipeline using Pytorch\n",
    "\n",
    "- The model we have used  is simple enough to code directly. \n",
    "- We only needed Pytorch to compute the loss and gradients. \n",
    "- For more complicated models this process becomes unwieldy. \n",
    "- We can use Pytorch to abstract away the details.  \n",
    "- The abstractions offered by Pytorch are illustrated below to solve the same problem that we just did. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E1baF5ll16Q3",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The model\n",
    "\n",
    "- The model we plan to use is encapsulated in a class that **inherits** from ```torch.nn.Module```\n",
    "\n",
    "- All we need to do is **override** two methods:\n",
    "1. ```__init__```. As you would have guessed this is called when the object is constructed to initialize our model\n",
    "1. ``` forward```. This is called to perform a forward computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5LlED-xrgbiJ",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class Net(nn.Module):\n",
    "  def __init__(self,in_features,out_features):\n",
    "    super(Net, self).__init__()\n",
    "    self.input_size=in_features\n",
    "    self.output_size=out_features\n",
    "    # declaring weights and bias as parameters so that they are included\n",
    "    # in the return value of .parameters()\n",
    "    self.weights=nn.Parameter(torch.randn(in_features,requires_grad=True,dtype=torch.float32))\n",
    "    self.bias=nn.Parameter(torch.tensor(0.,requires_grad=True,dtype=torch.float32))\n",
    "    #self.layer=nn.Linear(self.input_size,self.output_size,bias=True)\n",
    "  def forward(self,input):  \n",
    "    y_hat=input.flatten(start_dim=1)\n",
    "    y_hat=torch.matmul(y_hat,self.weights)+self.bias\n",
    "    y_hat=torch.sigmoid(y_hat)\n",
    "    return y_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tm160c2I23J3",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Note that in the initialization, the weights and bias are constructed as ```Parameter```. \n",
    "- This is so that we can use the ```.parameters()``` call and pass it to the optimizer.\n",
    "- Next we create an instance of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y9_n6Y2N00Io",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "model=Net(3*32*32,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KKkSOrAn35u5",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Recall that each learning iteration performs a number of steps. \n",
    "1. Compute the forward pass over the input to get the output. This is now done using ```model.forward()``` indirectly by calling ```model(input)```\n",
    "1. Compute the loss using an appropriate loss function. Same as before\n",
    "1. Compute the gradients using ```loss.backward()```.\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- ```backward()``` computes the gradient with respect to the parameters AND saves them in the ```.grad``` attributes\n",
    "- For example, if ```p``` is a parameters then ```loss.backward()``` computes the gradient of ```loss``` wrt ```p``` AND saves the result in ```p.grad```\n",
    "- Once the gradients are computed\n",
    "1. The optimizer updates the parameters. \n",
    "    - This is done by the optimizer using ```optimizer.step()```. \n",
    "1. This is important since later on we will use optimizers that use a different strategy to update the parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8L9FtlGbz1S3",
    "outputId": "a8377b80-f564-4d1b-dfef-eeabdfdeeaeb",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "rate=0.015\n",
    "\n",
    "import torch.optim as optim\n",
    "optimizer=optim.SGD(model.parameters(),lr=rate)\n",
    "loss_fn=torch.nn.BCELoss()\n",
    "epochs=10\n",
    "for epoch in range(epochs):\n",
    "  for imgs,labels in train_loader:\n",
    "  # uses the .forward() method to get y_hat\n",
    "    y_hat=model(imgs)\n",
    "  # as before\n",
    "    loss=loss_fn(y_hat,labels.float())\n",
    "  # Computes the gradients and saves them in the appropriate .grad\n",
    "    loss.backward()\n",
    "  # updates the parameters using the computed .grad\n",
    "    optimizer.step()\n",
    "  # zero the .grad values so that they don't accumulate\n",
    "    optimizer.zero_grad()\n",
    "  \n",
    "  print(\"loss {:.4f}\".format(loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def predict(loader):\n",
    "    total=0.\n",
    "    for imgs,labels in loader:\n",
    "        outputs=model(imgs)\n",
    "        ones=outputs>0.5\n",
    "        r=ones==labels\n",
    "        total+=r.sum()\n",
    "    # Compute vector \"y_hat\" predicting\n",
    "    # the probabilities of a machine being present in the picture\n",
    "    \n",
    "    return total/len(loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(test_loader)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "colab": {
   "authorship_tag": "ABX9TyNuNqO6ce7qryqS+HxdL/2J",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "81794d4967e6c3204c66dcd87b604927b115b27c00565d3d43f05ba2f3a2cb0d"
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "10a2f8fa1176415eb1427954d02ac81e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1fe3e0a792204b568fdeada38bff559a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "716eed7ac5b242b1a43d095c0376fdfd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_eff7dac6203a4409bd25e5a0fafbfe5f",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_ffe956b562a148a9abb63f496ce91030",
      "value": " 170498071/170498071 [00:02&lt;00:00, 73485295.02it/s]"
     }
    },
    "9daf573e127d45b0a13d392d625f6dd7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_df2a9b2f02d2434682d4ca213568fbc9",
       "IPY_MODEL_ffce6ae3a0f14491a4690ddec0df4674",
       "IPY_MODEL_716eed7ac5b242b1a43d095c0376fdfd"
      ],
      "layout": "IPY_MODEL_10a2f8fa1176415eb1427954d02ac81e"
     }
    },
    "c25206d0d8be44e3b18028c61228dbd4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c49c0f939d094f8bb00e028bcae134cb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "df2a9b2f02d2434682d4ca213568fbc9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fc2f840078b44934a9a0a972b2d1a6aa",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_c49c0f939d094f8bb00e028bcae134cb",
      "value": "100%"
     }
    },
    "eff7dac6203a4409bd25e5a0fafbfe5f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fc2f840078b44934a9a0a972b2d1a6aa": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ffce6ae3a0f14491a4690ddec0df4674": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c25206d0d8be44e3b18028c61228dbd4",
      "max": 170498071,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_1fe3e0a792204b568fdeada38bff559a",
      "value": 170498071
     }
    },
    "ffe956b562a148a9abb63f496ce91030": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
